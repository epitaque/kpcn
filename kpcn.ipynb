{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd05a9bf6c2315224b3b5934bc5e2f4700a7f472676904979a496b583b6d22b6a00",
   "display_name": "Python 3.8.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "b84e518aba231f393e9936d1511cdf75e721f3ed64b5041a4277cd671c20c953"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "pip install tensorflow  \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import imageio\n",
    "import math\n",
    "\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 64\n",
    "batch_size = 10\n",
    "percent_used_for_validation = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_7\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nzero_padding2d_42 (ZeroPaddi (None, 68, 68, 40)        0         \n_________________________________________________________________\nconv2d_40 (Conv2D)           (None, 64, 64, 100)       100100    \n_________________________________________________________________\nzero_padding2d_43 (ZeroPaddi (None, 68, 68, 100)       0         \n_________________________________________________________________\nconv2d_41 (Conv2D)           (None, 64, 64, 100)       250100    \n_________________________________________________________________\nzero_padding2d_44 (ZeroPaddi (None, 68, 68, 100)       0         \n_________________________________________________________________\nconv2d_42 (Conv2D)           (None, 64, 64, 100)       250100    \n_________________________________________________________________\nzero_padding2d_45 (ZeroPaddi (None, 68, 68, 100)       0         \n_________________________________________________________________\nconv2d_43 (Conv2D)           (None, 64, 64, 100)       250100    \n_________________________________________________________________\nzero_padding2d_46 (ZeroPaddi (None, 68, 68, 100)       0         \n_________________________________________________________________\nconv2d_44 (Conv2D)           (None, 64, 64, 100)       250100    \n_________________________________________________________________\nzero_padding2d_47 (ZeroPaddi (None, 68, 68, 100)       0         \n_________________________________________________________________\nconv2d_45 (Conv2D)           (None, 64, 64, 100)       250100    \n_________________________________________________________________\nzero_padding2d_48 (ZeroPaddi (None, 68, 68, 100)       0         \n_________________________________________________________________\nconv2d_46 (Conv2D)           (None, 64, 64, 100)       250100    \n_________________________________________________________________\nzero_padding2d_49 (ZeroPaddi (None, 68, 68, 100)       0         \n_________________________________________________________________\nconv2d_47 (Conv2D)           (None, 64, 64, 3)         7503      \n=================================================================\nTotal params: 1,608,203\nTrainable params: 1,608,203\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def make_nn():\n",
    "    L = 9\n",
    "    kernel_size = 5\n",
    "    input_channels = 40\n",
    "    hidden_channels = 100\n",
    "    in_between_layers = 7\n",
    "    # output_kernel_size = 28\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(patch_size, patch_size, input_channels)))\n",
    "    for i in range(in_between_layers):\n",
    "        model.add(keras.layers.ZeroPadding2D(padding=(2, 2)))\n",
    "        model.add(layers.Conv2D(hidden_channels, kernel_size=kernel_size, strides=1, activation=\"relu\"))\n",
    "    model.add(keras.layers.ZeroPadding2D(padding=(2, 2)))\n",
    "    # model.add(layers.Conv2D(output_kernel_size**2, kernel_size=kernel_size, strides=1, activation=\"relu\"))\n",
    "    model.add(layers.Conv2D(3, kernel_size=kernel_size, strides=1, activation=\"relu\"))\n",
    "    model.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "    return model;\n",
    "model = make_nn()\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_color(color, albedo, epsilon=0.00316):\n",
    "    return color * (albedo + epsilon)\n",
    "\n",
    "def calculate_gradient(image):\n",
    "    y, x, c = image.shape\n",
    "    dx = image[:, 1:, :] - image[:, :x-1, :]\n",
    "    dy = image[1:, :, :] - image[:y-1, :, :]\n",
    "    dx = np.append(dx, np.zeros([y, 1, c]), axis=1)\n",
    "    dy = np.append(dy, np.zeros([1, x, c]), axis=0)\n",
    "    grad = np.dstack((dx, dy))\n",
    "    return grad\n",
    "\n",
    "def load_highspp(folder_path):\n",
    "    albedo = imageio.imread(folder_path + \"/albedo.png\")\n",
    "    color = imageio.imread(folder_path + \"/color.png\")\n",
    "    color = preprocess_color(color, albedo)\n",
    "    return color\n",
    "\n",
    "def load_lowspp(folder_path):\n",
    "    # albedo buffers\n",
    "    albedo = imageio.imread(folder_path + \"/albedo.png\")\n",
    "    albedo_variance = imageio.imread(folder_path + \"/albedoVariance.png\")\n",
    "    albedo_gradient = calculate_gradient(albedo)\n",
    "\n",
    "    # color buffers\n",
    "    color = imageio.imread(folder_path + \"/color.png\")\n",
    "    color = preprocess_color(color, albedo)\n",
    "    color_variance = imageio.imread(folder_path + \"/colorVariance.png\")\n",
    "    color_gradient = calculate_gradient(color)\n",
    "\n",
    "    # depth buffers\n",
    "    depth = imageio.imread(folder_path + \"/depth.png\")\n",
    "    depth = depth.reshape((depth.shape[0], depth.shape[1], 1))\n",
    "    depth_variance = imageio.imread(folder_path + \"/depthVariance.png\")\n",
    "    depth_gradient = calculate_gradient(depth)\n",
    "\n",
    "    # normal buffers\n",
    "    normal = imageio.imread(folder_path + \"/normal.png\")\n",
    "    normal_variance = imageio.imread(folder_path + \"/normalVariance.png\")\n",
    "    normal_gradient = calculate_gradient(normal)\n",
    "\n",
    "\n",
    "    combined = np.dstack((albedo, albedo_variance, albedo_gradient, color, color_variance, color_gradient, depth, depth_variance, depth_gradient, normal, normal_variance, normal_gradient))\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split full res image into patch_size * patch_size images\n",
    "def get_patches(image):\n",
    "    x_patches = math.floor(image.shape[0]/patch_size)\n",
    "    y_patches = math.floor(image.shape[1]/patch_size)\n",
    "    patches = []\n",
    "    for x in range(x_patches):\n",
    "        for y in range(y_patches):\n",
    "            xstart = x * patch_size\n",
    "            xend = xstart + patch_size\n",
    "            ystart = y * patch_size\n",
    "            yend = ystart + patch_size\n",
    "            temp = image[xstart:xend, ystart:yend, :]\n",
    "            patches.append(temp)\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data():\n",
    "    x_patches = []\n",
    "    y_patches = []\n",
    "    orig = next(os.walk('./pngs'))[1]\n",
    "    folders = [x[0:x.rindex('16')] for x in orig if '16' in x]\n",
    "\n",
    "    for x in folders:\n",
    "        low_spp = load_lowspp('./pngs/' + x + '16')\n",
    "        high_spp = load_reference('./pngs/' + x + '4096')\n",
    "        residual = high_spp - low_spp[:, :, 12:15]\n",
    "        x_patches = x_patches + get_patches(low_spp)\n",
    "        y_patches = y_patches + get_patches(residual)\n",
    "    \n",
    "    validate_amount = math.floor(len(x_patches) * percent_used_for_validation)\n",
    "    rec_count = len(x_patches)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((x_patches, y_patches))\n",
    "    ds = ds.shuffle(buffer_size=rec_count)\n",
    "    train = ds.skip(validate_amount).batch(batch_size)\n",
    "    validate = ds.take(validate_amount).batch(batch_size)\n",
    "    \n",
    "    return train, validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['bathroom2-', 'bathroom', 'bedroom-', 'car-', 'car2-', 'classroom-', 'coffee-', 'cornell-box-', 'curly-hair-', 'dining-room-', 'dragon-', 'furball-', 'glass-of-water-', 'house-', 'kitchen-', 'lamp-', 'living-room-2-', 'living-room-3-', 'living-room-', 'material-testball-', 'spaceship-', 'staircase-', 'staircase2-', 'teapot-', 'teapot-full-', 'veach-ajar-', 'veach-bidir-', 'veach-mis-', 'volumetric-caustic-', 'water-caustic-']\n"
     ]
    }
   ],
   "source": [
    "# train, validate = prepare_training_data()\n",
    "prepare_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/10\n",
      "19/19 [==============================] - 5s 280ms/step - loss: 3631.1216 - accuracy: 0.6040 - val_loss: 3977.7505 - val_accuracy: 0.5618\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 4s 129ms/step - loss: 3727.0281 - accuracy: 0.5874 - val_loss: 3682.0820 - val_accuracy: 0.5924\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 2s 123ms/step - loss: 3678.7551 - accuracy: 0.6059 - val_loss: 2965.6638 - val_accuracy: 0.5606\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 2s 126ms/step - loss: 4019.6455 - accuracy: 0.5949 - val_loss: 5245.5498 - val_accuracy: 0.5845\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 4s 205ms/step - loss: 3706.0715 - accuracy: 0.6028 - val_loss: 3256.2471 - val_accuracy: 0.6152\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 2s 128ms/step - loss: 3999.0996 - accuracy: 0.6048 - val_loss: 2484.3816 - val_accuracy: 0.6212\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 2s 123ms/step - loss: 3725.5701 - accuracy: 0.5880 - val_loss: 3640.7229 - val_accuracy: 0.5731\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 2s 128ms/step - loss: 3533.4648 - accuracy: 0.5947 - val_loss: 3838.5891 - val_accuracy: 0.5966\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 2s 127ms/step - loss: 3988.2834 - accuracy: 0.5940 - val_loss: 4013.1548 - val_accuracy: 0.5597\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 3s 56ms/step - loss: 3923.1116 - accuracy: 0.6005 - val_loss: 3786.3811 - val_accuracy: 0.5598\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    train,\n",
    "    validation_data=validate,\n",
    "    batch_size=batch_size,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}