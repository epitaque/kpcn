{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install tensorflow  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import imageio\n",
    "import math\n",
    "import IPython.display\n",
    "import PIL\n",
    "\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(data):\n",
    "    data = np.clip(data, 0.0, 255.0).astype(np.uint8)\n",
    "    pil_img = PIL.Image.fromarray(data, 'RGB')\n",
    "    display(pil_img)\n",
    "    return pil_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build input shape: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7, 7), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyDenseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_outputs):\n",
    "        super(MyDenseLayer, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        print(\"build input shape: \" + str(input_shape[-1]))\n",
    "        self.kernel = self.add_weight(\"kernel\",\n",
    "                                      shape=[int(input_shape[-1]),\n",
    "                                             self.num_outputs])\n",
    "\n",
    "#     @tf.function\n",
    "#     def f(x):\n",
    "#         while tf.reduce_sum(x) > 1:\n",
    "#             tf.print(x)\n",
    "#             x = tf.tanh(x)\n",
    "#         return x\n",
    "\n",
    "    def call(self, input):\n",
    "        #         print(\"build input shape: \" + str(input_shape))\n",
    "        l = input.shape[0] + 2\n",
    "        kernel = tf.zeros([l, l])\n",
    "        for i in range(input.shape[-1])\n",
    "            temp = input[i,1]\n",
    "            temp = tf.pad(temp,)\n",
    "            kernel = kernel + input[i,1]\n",
    "        #     kernel = tf.pad(kernel, tf.constant([[1, 1]]), \"CONSTANT\")\n",
    "        #     kernel = tf.linalg.diag(kernel, k=0)\n",
    "\n",
    "        paddings = tf.constant([[1, 1], [0, 0]])\n",
    "\n",
    "        output = input[:,:1]\n",
    "        output = tf.pad(output, paddings, \"CONSTANT\")\n",
    "\n",
    "        #     return tf.tensordot(output, kernel, axes=[[1], [0]])\n",
    "\n",
    "        return kernel \n",
    "\n",
    "layer = MyDenseLayer(5)\n",
    "x = tf.ones([5, 2]) * 0.5\n",
    "layer(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-f37ca8d3f8f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpercent_used_for_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcheckpoint_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"training_2/cp.ckpt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mcheckpoint_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "patch_size = 64\n",
    "mini_batch_size = 5\n",
    "percent_used_for_validation = 0.1\n",
    "checkpoint_path = \"training_2/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_3_channels(image):\n",
    "    if image.ndim == 2: image = np.dstack((image, image, image))\n",
    "    image = image[:,:,:3]\n",
    "    return image\n",
    "\n",
    "def preprocess_color(color, albedo, epsilon=0.00316):\n",
    "    return color.astype(np.float32) / (albedo + epsilon)\n",
    "\n",
    "def postprocess_color(color, albedo, epsilon=0.00316):\n",
    "    return color * (albedo + epsilon)\n",
    "\n",
    "def preprocess_color_variance(variance, albedo, epsilon=0.00316):\n",
    "    return variance / (albedo + epsilon)**2\n",
    "\n",
    "def calculate_gradient(image):\n",
    "    y, x, c = image.shape\n",
    "    dx = image[:, 1:, :] - image[:, :x-1, :]\n",
    "    dy = image[1:, :, :] - image[:y-1, :, :]\n",
    "    dx = np.append(dx, np.zeros([y, 1, c]), axis=1)\n",
    "    dy = np.append(dy, np.zeros([1, x, c]), axis=0)\n",
    "    grad = np.dstack((dx, dy))\n",
    "    return grad\n",
    "\n",
    "def load_highspp(folder_path):\n",
    "    albedo = make_3_channels(imageio.imread(folder_path + \"/albedo.png\").astype(np.float32))\n",
    "    color = make_3_channels(imageio.imread(folder_path + \"/color.png\").astype(np.float32))\n",
    "    # color = preprocess_color(color, albedo)\n",
    "    return color\n",
    "\n",
    "def load_lowspp(folder_path):\n",
    "    print(\"loading \" + folder_path)\n",
    "\n",
    "    # albedo buffers\n",
    "    albedo = make_3_channels(imageio.imread(folder_path + \"/albedo.png\").astype(np.float32))\n",
    "    # albedo_variance = make_3_channels(imageio.imread(folder_path + \"/albedoVariance.png\").astype(np.float32))\n",
    "    # albedo_gradient = calculate_gradient(albedo)\n",
    "\n",
    "    # color buffers\n",
    "    color = make_3_channels(imageio.imread(folder_path + \"/color.png\").astype(np.float32))\n",
    "    # color = preprocess_color(color, albedo)\n",
    "    color_variance = make_3_channels(imageio.imread(folder_path + \"/colorVariance.png\").astype(np.float32))\n",
    "    # color_variance = preprocess_color_variance(color_variance, albedo)\n",
    "    color_gradient = calculate_gradient(color)\n",
    "\n",
    "    # depth buffers\n",
    "    depth = imageio.imread(folder_path + \"/depth.png\").astype(np.float32)\n",
    "    depth = depth.reshape((depth.shape[0], depth.shape[1], 1))\n",
    "    # depth_variance = imageio.imread(folder_path + \"/depthVariance.png\").astype(np.float32)\n",
    "    # depth_gradient = calculate_gradient(depth)\n",
    "\n",
    "    # normal buffers\n",
    "    normal = make_3_channels(imageio.imread(folder_path + \"/normal.png\").astype(np.float32))\n",
    "    # normal_variance = make_3_channels(imageio.imread(folder_path + \"/normalVariance.png\").astype(np.float32))\n",
    "    # normal_gradient = calculate_gradient(normal)\n",
    "\n",
    "    # combined = np.dstack((albedo, albedo_gradient, color, color_variance, color_gradient, depth, depth_variance, depth_gradient, normal, normal_variance, normal_gradient))\n",
    "    combined = np.dstack((color, color_variance, color_gradient, albedo, depth, normal))\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split full res image into patch_size * patch_size images\n",
    "def get_patches(image):\n",
    "    x_patches = math.floor(image.shape[0]/patch_size)\n",
    "    y_patches = math.floor(image.shape[1]/patch_size)\n",
    "    patches = []\n",
    "    for x in range(x_patches):\n",
    "        for y in range(y_patches):\n",
    "            xstart = x * patch_size\n",
    "            xend = xstart + patch_size\n",
    "            ystart = y * patch_size\n",
    "            yend = ystart + patch_size\n",
    "            temp = image[xstart:xend, ystart:yend, :]\n",
    "            patches.append(temp)\n",
    "        patches.append(image[xstart:xend, image.shape[1]-patch_size:, :])\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_mostly_black(patch):\n",
    "    return np.mean(patch[:,:,:3].flatten(), axis=0) < 10.0\n",
    "\n",
    "# note to self: use this https://www.tensorflow.org/api_docs/python/tf/data/experimental/sample_from_datasets\n",
    "def load_x_y_patches():\n",
    "    x_patches = []\n",
    "    y_patches = []\n",
    "    orig = next(os.walk('./pngs'))[1]\n",
    "    folders = [x[0:x.rindex('16')] for x in orig if '16' in x]\n",
    "\n",
    "    for x in folders:\n",
    "        low_spp = load_lowspp('./pngs/' + x + '16')\n",
    "        high_spp = load_highspp('./pngs/' + x + '4096')\n",
    "        # residual = high_spp - low_spp[:, :, 12:15]\n",
    "        temp_x_patches = get_patches(low_spp)\n",
    "        temp_y_patches = get_patches(high_spp)\n",
    "\n",
    "        for i in range(len(temp_x_patches)):\n",
    "            if not is_mostly_black(temp_y_patches[0]):\n",
    "                x_patches.append(temp_x_patches[i])\n",
    "                residual = temp_y_patches[i] - temp_x_patches[i][:,:,:3]\n",
    "                # y_patches.append(residual)\n",
    "                y_patches.append(temp_y_patches[i])\n",
    "    \n",
    "    return x_patches, y_patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_patches, y_patches = load_x_y_patches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_patches[0].shape\n",
    "# for i in range(1400, 1405):\n",
    "#     residual = y_patches[i][:,:,:3]\n",
    "#     x_patch = x_patches[i][:,:,:3]\n",
    "#     total = x_patch + residual\n",
    "\n",
    "#     imshow(total.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_nn(input_channels):\n",
    "    #basic model parameters\n",
    "    L = 9\n",
    "    kernel_size = 5\n",
    "    hidden_channels = 100\n",
    "    output_kernel_size = 21\n",
    "    in_between_layers = L - 2\n",
    "\n",
    "    # add layers\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(patch_size, patch_size, input_channels)))\n",
    "    for i in range(in_between_layers):\n",
    "        model.add(keras.layers.ZeroPadding2D(padding=(2, 2)))\n",
    "        model.add(layers.Conv2D(hidden_channels, kernel_size=kernel_size, kernel_initializer=\"glorot_uniform\", strides=1, activation=\"relu\"))\n",
    "    model.add(keras.layers.ZeroPadding2D(padding=(2, 2)))\n",
    "    model.add(layers.Conv2D(3, kernel_size=kernel_size, kernel_initializer=\"glorot_uniform\", strides=1, activation=\"relu\"))\n",
    "\n",
    "    # compile model\n",
    "    opt = keras.optimizers.Adam(learning_rate=10e-5)\n",
    "    model.compile(loss=\"mean_absolute_error\", optimizer=opt, metrics=['mean_absolute_error'])\n",
    "    return model;\n",
    "\n",
    "model = make_nn(x_patches[0].shape[2])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(400, 410):\n",
    "#     imshow((x_patches[i])[:,:,12:15].astype(np.uint8))\n",
    "#     imshow((y_patches[i])[:,:,:].astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_dataset(x_patches, y_patches):\n",
    "    validate_amount = math.floor(len(x_patches) * percent_used_for_validation)\n",
    "    rec_count = len(x_patches)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((x_patches, y_patches))\n",
    "    ds = ds.shuffle(buffer_size=400, reshuffle_each_iteration=True)\n",
    "    train = ds.skip(validate_amount).batch(mini_batch_size)\n",
    "    validate = ds.take(validate_amount).batch(mini_batch_size)\n",
    "    return train, validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, validate = prepare_training_data()\n",
    "train, validate = create_tf_dataset(x_patches, y_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayImageCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super(DisplayImageCallback, self).__init__()\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 3 != 0:\n",
    "            return\n",
    "\n",
    "        # if predicting final output\n",
    "        pn = 405\n",
    "        xpatch = x_patches[pn]\n",
    "        xpatchcolor = xpatch[:,:,:3]\n",
    "        predicted = model.predict(xpatch.reshape((1, xpatch.shape[0], xpatch.shape[1], xpatch.shape[2])))[0]\n",
    "        gt = y_patches[pn]\n",
    "\n",
    "        imshow(xpatchcolor).save(checkpoint_dir + '/xpatch.png')\n",
    "        imshow(gt).save(checkpoint_dir + '/gt.png')\n",
    "        imshow(predicted).save(checkpoint_dir + '/prediction.png')\n",
    "\n",
    "\n",
    "# xpatch = x_patches[pn]\n",
    "# xpatchcolor = xpatch[:,:,:3]\n",
    "# predicted = model.predict(xpatch.reshape((1, xpatch.shape[0], xpatch.shape[1], xpatch.shape[2])))[0]\n",
    "# gt = y_patches[pn]\n",
    "\n",
    "# imshow(xpatchcolor).save(checkpoint_dir + '/xpatch.png')\n",
    "# imshow(gt).save(checkpoint_dir + '/gt.png')\n",
    "# imshow(predicted).save(checkpoint_dir + '/prediction.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fit model on training data\")\n",
    "image_cb = DisplayImageCallback()\n",
    "history_cb = tf.keras.callbacks.CSVLogger('./training_2/log.csv', separator=\",\", append=True)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "history = model.fit(\n",
    "    train,\n",
    "    validation_data=validate,\n",
    "    epochs=10000,\n",
    "    callbacks=[cp_callback, history_cb, image_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.layers[1].get_weights()[0])\n",
    "# model.predict(xpatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newpatch = x_patches[1350] #np.reshape(x_patches[1350], (1, 64, 64, 40))\n",
    "newpatch = np.stack((newpatch, newpatch, newpatch, newpatch, newpatch), axis=0)\n",
    "newpatch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn = 405\n",
    "xpatch = x_patches[pn]\n",
    "xpatch = np.stack((xpatch, xpatch, xpatch, xpatch, xpatch), axis=0)\n",
    "prediction = model.predict(xpatch)\n",
    "prediction\n",
    "xpatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imshow((prediction[0] * 255.0).astype(np.uint8))\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "2cd2abeaea65c445b1f865368dbbfc01b247d4af0d8b7b9288cea8582e68bfb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
